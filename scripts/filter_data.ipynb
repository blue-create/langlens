{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Rc9aGvqmOAs96y9-MxjgQa8GP654qrXo",
      "authorship_tag": "ABX9TyNg5Dy9L1BgrA2nybHRQZg3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Paths"
      ],
      "metadata": {
        "id": "v-WYH-pGXIba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm \n",
        "import re\n"
      ],
      "metadata": {
        "id": "EQ5jnX8vJY1N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set paths\n",
        "%cd drive/MyDrive/Work/Frontline/data/"
      ],
      "metadata": {
        "id": "StpYX7PXJRqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b421a8bf-9983-429b-c98f-c69a5a3cb021"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1WfnZsqpG1r110J63sMbfS5TpsDOkveiV/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect with google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "l6zf1fTOTgMF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Methods and Constants"
      ],
      "metadata": {
        "id": "nLR9xXsihJL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# methods\n",
        "\n",
        "def filter_strings(text, combination_list):\n",
        "  \"\"\" function to compare if any of a list of words occur in a text or or list of texts \n",
        "  Parameters:\n",
        "    - text (str or list of str): text which is checked \n",
        "    - combination_list (list of str): list of words which are checked if they occur in text \n",
        "  Returns:\n",
        "    - boolean: True or False depending on if any of the words in combination_list occurs in text\n",
        "  \"\"\"\n",
        "\n",
        "  text=\"\".join(text).lower()\n",
        "  combinations = combination_list\n",
        "  for comb in combinations:\n",
        "    \n",
        "    if all(word in text for word in comb.split(\" und \")):\n",
        "        return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "ugnHlDF1Z0VO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comb1 = ['häusliche gewalt',\n",
        "        'partnerschaftsgewalt',\n",
        "        'partnergewalt',\n",
        "        'femizid',\n",
        "        'beziehungstat',\n",
        "        'liebesdrama',\n",
        "        'ehedrama',\n",
        "        'liebestragödie',\n",
        "        'eheliche gewalt',\n",
        "        'ehekrieg',\n",
        "        'innerfamiliäre gewalt',\n",
        "        'innerhäusliche gewalt',\n",
        "        'gewalt und ehe',\n",
        "        'ehe und hölle'\n",
        "        'gewalt und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'vergewaltigen und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'vergewaltigung und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'missbrauch und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'missbräuchlich und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'gewalttätig und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'verletzung und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'verletzen und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'übergriffig und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'drohung und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'drohen und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'manipulation und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'manipulieren und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'beleidigen und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'beleidigung und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'gaslighting und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'schlagen und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'zwingen und (freund(in)?|partner(in)?|mann|frau)\\s', \n",
        "        'gezwungen und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'zwang und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'einsperren und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'stalking und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'stalken und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'kontrollieren und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'kontrolle und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'isolieren und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'isolation und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'hauen und (freund(in)?|partner(in)?|mann|frau)\\s',\n",
        "        'ohrfeige und (freund(in)?|partner(in)?|mann|frau)\\s'\n",
        "\n",
        "        ]"
      ],
      "metadata": {
        "id": "xRyLzbCkXa6M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_if_complete(prefix):\n",
        "  \"\"\" function to compare if json contains all available articles\n",
        "  Parameters:\n",
        "    - prefix (str): prefix of the journal that is checked for completeness\n",
        "  Returns:\n",
        "    - tuple (boolean, DataFrame)\n",
        "      - boolean indicates weather or not the json file is complete\n",
        "      - DataFrame returns the json data if its complete and None if incomplete\n",
        "  \"\"\"\n",
        "  try:\n",
        "    df=pd.read_json(os.path.join(\"json\",prefix+\".json\"))\n",
        "    # compare size of dataframe to number of articles\n",
        "    if len(df)==art_per_src[prefix]:\n",
        "      return (True,df)\n",
        "    else:\n",
        "      print(f\"Number of articles in {prefix} json should be {art_per_src[prefix]} but is {len(df)}.\")\n",
        "      return (False, None)\n",
        "  except:\n",
        "    print(f\"Error while parsing {prefix}\")\n",
        "    return (False, None)"
      ],
      "metadata": {
        "id": "Tr4XkPuUXSRL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_if_exported(prefix):\n",
        "  \"\"\" function to check if the relevant articles of a journal have been exported already\n",
        "  Parameters:\n",
        "    - prefix (str): prefix of the journal that is checked\n",
        "  Returns:\n",
        "    - boolean: returns True if the relevant articles of a journal have been exported already, False otherwise\n",
        "  \"\"\"\n",
        "  filtered=os.listdir(\"filtered\")\n",
        "  filtered = [file.split(\".\")[0]for file in filtered if file.endswith(\".csv\")]\n",
        "  if prefix in filtered:\n",
        "    return True\n",
        "  else: \n",
        "    return False\n"
      ],
      "metadata": {
        "id": "CWShosAunWK_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Data Extraction"
      ],
      "metadata": {
        "id": "Lcf3UAKTQqHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary saving the number of articles per prefix usingthe xml names eg. MIB_250001_260000.xml\n",
        "\n",
        "art_per_src={}\n",
        "# list of all prefixes\n",
        "prefixes= sorted([i.split(\".\")[0] for i in os.listdir(\"Raw\")])\n",
        "# list of all xml files\n",
        "xmls=os.listdir(\"unzipped\")\n",
        "for prefix in prefixes:\n",
        "  # list of number of articles of prefix by title name\n",
        "  n_art=sorted([int(re.split(\"_|\\.\",xml)[-2]) for xml in xmls if xml.startswith(prefix)])\n",
        "  # save the largest number (total number of articles pf that prefix) or 0 if no xml of that prefix present\n",
        "  n_art = n_art[-1] if len(n_art)>0 else 0\n",
        "  art_per_src[prefix]=n_art\n",
        "# eg. prefix ANN has 352'684 articles\n",
        "art_per_src[\"AAN\"]"
      ],
      "metadata": {
        "id": "mUjev1bbR18H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42889cc-c8c4-4023-ea14-a70e093a820f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352684"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter based on key words"
      ],
      "metadata": {
        "id": "scwGO75nXejG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, all json files are looked at. Only if they are complete, ie. they contain all available articles, they are considered i nthe filtering, else the file is skipped. The filtering is based on a list of word combinations related to domestic violence. If an article contains any of these combinations, it is added to a dictionary. \n",
        "\n",
        "Note: If the json file has been previsouly filtered and the relevant articles were already exported, they are skipped as well.\n"
      ],
      "metadata": {
        "id": "pbwY9XOxkrnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# empty dictionary for DV articles\n",
        "DV_art={}\n",
        "for file in tqdm(sorted(os.listdir(\"json\"))):\n",
        "  #looping through all json files\n",
        "  if file.endswith(\".json\"):\n",
        "    prefix=file.split(\".\")[0]\n",
        "    # checking if the json file is complete i.e. contains all available articles\n",
        "    is_complete, df_temp=check_if_complete(prefix)\n",
        "    if is_complete and not check_if_exported(prefix):\n",
        "      #if the file is complete the articles containing DV key words are filtered out\n",
        "      for row_j in range(len(df_temp)):\n",
        "        if prefix not in DV_art:\n",
        "            DV_art[prefix]=[]\n",
        "        if filter_strings(df_temp.loc[row_j,:][\"text\"],comb1):\n",
        "          # DV articles are added to a dictionary\n",
        "          DV_art[prefix].append(df_temp.loc[row_j,:])"
      ],
      "metadata": {
        "id": "GAld8LC_YqJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a9a2f3b-2eef-4083-a676-f6c3b367c3e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:12<00:00, 12.96s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exporting relevant Articles\n",
        "In this step all articles that are relaed to domestic relevance are exported as csv, using their prefix as file name. Journals with no relevant articles are exportes as well, with an empty csv to keep track of the filtering. "
      ],
      "metadata": {
        "id": "mwcL5Ee9lzmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key in DV_art.keys():\n",
        "  pd.DataFrame(DV_art[key]).to_csv(\"filtered/\"+key+\".csv\")"
      ],
      "metadata": {
        "id": "FEvK8pyWlzN0"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}
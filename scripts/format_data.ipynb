{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKA8dIuQhxDAZPljauPDgx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EiZS90YvWYBt","executionInfo":{"status":"ok","timestamp":1680534061138,"user_tz":-120,"elapsed":18687,"user":{"displayName":"Victoria Waldersee","userId":"16072912239258907225"}},"outputId":"3df358bd-8b0e-4f08-dae5-7d9ad5cc463a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# connect with google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# access data \n","%cd /content/drive/MyDrive/Daten/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdHvzLHiXTk4","executionInfo":{"status":"ok","timestamp":1680515795880,"user_tz":-120,"elapsed":5,"user":{"displayName":"Victoria Waldersee","userId":"16072912239258907225"}},"outputId":"cba8d9ba-73b3-4194-93a3-840121c7a286"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Daten\n"]}]},{"cell_type":"code","source":["# check number of files \n","import os \n","\n","num_files = len(os.listdir(\".\"))\n","print(\"Number of files in the folder: \", num_files)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDLAdk9nWvNY","executionInfo":{"status":"ok","timestamp":1680515798490,"user_tz":-120,"elapsed":287,"user":{"displayName":"Victoria Waldersee","userId":"16072912239258907225"}},"outputId":"581a8f93-ac88-40f0-d5fd-f9ea21d3a22c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of files in the folder:  253\n"]}]},{"cell_type":"code","source":["# check if any folder is empty\n","empty_folders = []\n","\n","for root, dirs, files in os.walk('.'):\n","    if not dirs and not files:\n","        empty_folders.append(root)\n","\n","print(\"Empty folders:\")\n","for folder in empty_folders:\n","    print(folder)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sjKhfS0Yklw","executionInfo":{"status":"ok","timestamp":1680522132104,"user_tz":-120,"elapsed":357,"user":{"displayName":"Victoria Waldersee","userId":"16072912239258907225"}},"outputId":"1a4ee76a-40cf-4778-8a71-2a1331e60ec5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Empty folders:\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","dataset = pd.DataFrame(columns=['Filename', 'Type', 'Content'])\n","\n","for entry in sorted(os.listdir('.')):\n","    entry_path = os.path.join('.', entry)\n","    if os.path.isdir(entry_path):\n","        # Entry is a folder, add XML files in the folder to the dataset\n","        for file in sorted(os.listdir(entry_path)):\n","            if file.endswith('.xml'):\n","                file_path = os.path.join(entry_path, file)\n","                with open(file_path, 'r') as f:\n","                    content = f.read()\n","                dataset = dataset.append({'Filename': file, 'Type': 'XML', 'Content': content}, ignore_index=True)\n","    elif os.path.isfile(entry_path) and entry.endswith('.xml'):\n","        # Entry is an XML file, add it to the dataset\n","        with open(entry_path, 'r') as f:\n","            content = f.read()\n","        dataset = dataset.append({'Filename': entry, 'Type': 'XML', 'Content': content}, ignore_index=True)\n","\n","print(dataset.head())\n"],"metadata":{"id":"eNt4KPaHcpqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QhwqTQQHZ1nW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["things to do: \n","- connect to github \n","- create and store dataset \n","- do some descriptive analysis: number of articles per newspaper, number of newspapers, number of topics per newspaper, etc. \n","- do filtering: german newspapers only, DA related topics only \n","- topic analysis: run the filtered dataset through a generic topic model "],"metadata":{"id":"LownCWdKdW9g"}}]}
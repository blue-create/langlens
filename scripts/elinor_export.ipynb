{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYgEs9hvh6M+H83HGPyo/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blue-create/langlens/blob/main/scripts/elinor_export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose\n",
        "\n",
        "This file shows the steps we took to sample and create the annotation dataset."
      ],
      "metadata": {
        "id": "Q1MHyZaI09-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect with Google drive to access data \n",
        "\n",
        "In order to access the data, you first need to create a shortcut of the data folder to your own Gdrive. If you've been granted editing rights, you should be able to edit the content of the folder, i.e. add, move and delete data, create and rename folders, etc."
      ],
      "metadata": {
        "id": "QYjhPHYZ1MVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-gEE8t61TyI",
        "outputId": "ef3065da-640a-4310-dbd5-94eb3c2c8884"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# redirect the working directory of this script to the data folder\n",
        "%cd /content/drive/MyDrive/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG1MwJ4Y1U_h",
        "outputId": "5e3f4396-91e6-42d4-d7d3-8bc0f0e6984f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "Ej0F6zHR1Xz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm as tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = \"filtered2\""
      ],
      "metadata": {
        "id": "Pb-1q-dqzgQH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "\n",
        "# loop through files \n",
        "for filename in os.listdir(folder_path):\n",
        "    # if csv file, load and add to dfs  \n",
        "    if filename.endswith(\".csv\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "        dfs.append(df)\n",
        "\n",
        "# combine files in df\n",
        "df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "ktoRDGajzoqi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect data\n"
      ],
      "metadata": {
        "id": "LnID3c_t7ZUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgPmz-4T7aw6",
        "outputId": "7b03cd89-fe74-40e7-c873-c3afb1a6b176"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1247840, 9)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1247840 entries, 0 to 1247839\n",
            "Data columns (total 9 columns):\n",
            " #   Column      Non-Null Count    Dtype  \n",
            "---  ------      --------------    -----  \n",
            " 0   Unnamed: 0  1247840 non-null  object \n",
            " 1   artikel_id  1247840 non-null  object \n",
            " 2   name        1247840 non-null  object \n",
            " 3   jahrgang    1246781 non-null  object \n",
            " 4   datum       1247825 non-null  float64\n",
            " 5   ressort     1121457 non-null  object \n",
            " 6   titel       1166481 non-null  object \n",
            " 7   untertitel  571720 non-null   object \n",
            " 8   text        1247840 non-null  object \n",
            "dtypes: float64(1), object(8)\n",
            "memory usage: 85.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove first column \n",
        "df1 = df.drop(\"Unnamed: 0\", axis=1)"
      ],
      "metadata": {
        "id": "-tWQnYG3CG1c"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a random subset of the data "
      ],
      "metadata": {
        "id": "Ieb0Shf71cvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# size of subset we want \n",
        "number = 100"
      ],
      "metadata": {
        "id": "bGL1Cb9R8fLD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perc = number/df1.shape[0]\n",
        "df_subset = df1.sample(frac=perc, random_state=42)"
      ],
      "metadata": {
        "id": "_7qzAZDi778j"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhbZJTRh8ScI",
        "outputId": "c3ef2bc4-3497-4647-9dba-09d1a6867872"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 100 entries, 141433 to 1157830\n",
            "Data columns (total 8 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   artikel_id  100 non-null    object \n",
            " 1   name        100 non-null    object \n",
            " 2   jahrgang    100 non-null    object \n",
            " 3   datum       100 non-null    float64\n",
            " 4   ressort     89 non-null     object \n",
            " 5   titel       92 non-null     object \n",
            " 6   untertitel  37 non-null     object \n",
            " 7   text        100 non-null    object \n",
            "dtypes: float64(1), object(7)\n",
            "memory usage: 7.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjust format for export"
      ],
      "metadata": {
        "id": "5FJOlUvd1gHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove square brackets \n",
        "df_subset[\"text\"] = df_subset[\"text\"].apply(lambda x: x[1:-1] if (isinstance(x, str) and x.startswith(\"[\") and x.endswith(\"]\")) else x)\n",
        "# remove backward slashes\n",
        "df_subset['text'] = df_subset['text'].str.replace('\\\\', '', regex = False)\n"
      ],
      "metadata": {
        "id": "vvPEYNFg7-8X"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to split strings to list\n",
        "def split_to_list(s):\n",
        "    return s.split(\"', '\")"
      ],
      "metadata": {
        "id": "2PYSBtqxE5nW"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply function to whole column\n",
        "df_subset['text'] = df_subset['text'].apply(split_to_list)"
      ],
      "metadata": {
        "id": "D7LTol01E8ZV"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add new line to separate paragraphs \n",
        "df_subset['text'] = df_subset['text'].apply(lambda x: [char+'\\n' for char in x])"
      ],
      "metadata": {
        "id": "fzVFChcFLcfZ"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export as csv"
      ],
      "metadata": {
        "id": "0Go0cc9U1kpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"elinor\""
      ],
      "metadata": {
        "id": "ItHRtFVP9vl_"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.to_csv(output_path+\"/annotation_test.csv\", index=False, sep=\"\\t\", header=True)"
      ],
      "metadata": {
        "id": "dJO8Splt9raZ"
      },
      "execution_count": 113,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QYjhPHYZ1MVO"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose\n",
        "\n",
        "This file shows the steps we took to sample and create the annotation dataset."
      ],
      "metadata": {
        "id": "Q1MHyZaI09-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect with Google drive to access data \n",
        "\n",
        "In order to access the data, you first need to create a shortcut of the data folder to your own Gdrive. If you've been granted editing rights, you should be able to edit the content of the folder, i.e. add, move and delete data, create and rename folders, etc."
      ],
      "metadata": {
        "id": "QYjhPHYZ1MVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-gEE8t61TyI",
        "outputId": "897002f0-0c23-44ca-b0c4-7c0b4e0fd9b9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# redirect the working directory of this script to the data folder\n",
        "%cd /content/drive/MyDrive/Work/Frontline/data/\n",
        "#%cd /content/drive/MyDrive/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG1MwJ4Y1U_h",
        "outputId": "9d994748-2afe-4d35-b55b-89a6b03cbe97"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1WfnZsqpG1r110J63sMbfS5TpsDOkveiV/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "Ej0F6zHR1Xz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm as tqdm\n",
        "from collections import Counter\n",
        "import os\n",
        "import pandas as pd\n",
        "import re \n",
        "from ast import literal_eval\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = \"filtered_4_26\""
      ],
      "metadata": {
        "id": "Pb-1q-dqzgQH"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 1: get csv files "
      ],
      "metadata": {
        "id": "6Ny15n7AO8PV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dfs = []\n",
        "\n",
        "# loop through files \n",
        "for filename in os.listdir(folder_path):\n",
        "    # if csv file, load and add to dfs  \n",
        "    if filename.endswith(\".csv\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        # import csv with text as list object \n",
        "        df = pd.read_csv(file_path, index_col=0, converters={\"text\":literal_eval})\n",
        "        dfs.append(df)\n",
        "# combine files in df\n",
        "df_filtered = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "ktoRDGajzoqi"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a random subset of the data "
      ],
      "metadata": {
        "id": "Ieb0Shf71cvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# size of subset we want \n",
        "number = 1000"
      ],
      "metadata": {
        "id": "bGL1Cb9R8fLD"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample = df_filtered.sample(number,)# random_state=42)"
      ],
      "metadata": {
        "id": "_7qzAZDi778j"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 2: get a csv file"
      ],
      "metadata": {
        "id": "pFNlGnG7PD23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample_file = pd.read_csv('sample.csv', encoding='utf-8', index_col=0)"
      ],
      "metadata": {
        "id": "RP4BKUzjPIF5"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 3: Manually selected dataset of relevant articles\n",
        "--> ensuring that the dataset only contains relevant articles, espscially for testing"
      ],
      "metadata": {
        "id": "17Rx0STiu1nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_dv=df_filtered.loc[(11483,14044,62494,49199,11047,14948,10565,31059,58890,20347,55396,56389,5528,18532,59435,8035,27119,12788,59992,21477,10331,26314,45356,61023,31865,48960,44587,17992,14763,60043,20540,4563,13213,6751,43374,41018,38770,24654,21936,29297,1869,33163,60220,61232,57613,48979,33785,51576,8300,7675),:]"
      ],
      "metadata": {
        "id": "bbKfHRI1u7ag"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select Data\n",
        "--> specify which data set of the three above methods should be used in the following analysis"
      ],
      "metadata": {
        "id": "VXVyMc5mkWGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment for full data set\n",
        "df_subset=df_filtered\n",
        "\n",
        "# uncomment for random data of 100 from full data set\n",
        "#df_subset=df_sample\n",
        "\n",
        "# uncomment for sample data set from csv file\n",
        "# df_subset= df_sample_file\n",
        "\n",
        "# uncomment for manually selected articles \n",
        "# df_subset = subset_dv"
      ],
      "metadata": {
        "id": "5-OJXUYwkhZ2"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjust format for export"
      ],
      "metadata": {
        "id": "5FJOlUvd1gHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Methods"
      ],
      "metadata": {
        "id": "7Kwdv6Uim224"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reformat_article(art, min_words=5, max_words=125):\n",
        "  # remove genios styles \n",
        "  art = [re.sub(r'<.*?>', '', x) for x in art]\n",
        "\n",
        "  # remove new line characters and preceeding whitespaces\n",
        "  art = [x.strip() for x in art]\n",
        "\n",
        "  #remove empty paragraphs\n",
        "  art = [x for x in art if x.strip()]\n",
        "\n",
        "  #remove paragraphs that are too long\n",
        "  art = [x for x in art if len(x.split()) < max_words]\n",
        "\n",
        "  #remove paragraphs that are too short, ie. by default 3 or fewer words\n",
        "  art = [x for x in art if len(x.split()) >= min_words]  \n",
        "\n",
        "  return art"
      ],
      "metadata": {
        "id": "beTpoSVOZowg"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def occurs(word, text):\n",
        "  \"\"\" function to check if a words occurs in a text\n",
        "  Parameters:\n",
        "    - word (str): word that is searched for\n",
        "    - text (str): text that is searched in \n",
        "  Returns:\n",
        "    - boolean: returns True if word occurs in text, False otherwise\n",
        "  \"\"\"\n",
        "  if len(re.findall(word,text))>0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "P8xAVqhbYsQp"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_title(title):\n",
        "  \"\"\" function to filter article by title\n",
        "  Parameters:\n",
        "    - title (str): title that is checked\n",
        "  Returns:\n",
        "    - boolean: returns True if either\n",
        "        - there is no title\n",
        "        - the title does not contain any of the words in the list exclude_titles\n",
        "  \"\"\"\n",
        "  if type(title)!=str:\n",
        "    return True\n",
        "  title=title.strip()\n",
        "  for ex in exclude_titles:\n",
        "    if ex.lower() == title.lower(): \n",
        "      return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "EN5THognY36L"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning text:\n",
        "- remove newline characters\n",
        "- remove paragraphs if too long or short\n",
        "- remove genios styles \n",
        "- remove empty paragraphs\n",
        "- remove duplicate articles"
      ],
      "metadata": {
        "id": "1IRqAQmlPjPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset[\"text\"] = [ reformat_article(art) for art in df_subset[\"text\"]]"
      ],
      "metadata": {
        "id": "uGaaq0t53tzy"
      },
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove \"empty\" articles, that wereremove in the previous step\n",
        "df_subset=df_subset[df_subset['text'].notna()] \n",
        "df_subset=df_subset[df_subset['text'].apply(len)!=0]\n",
        "df_subset.shape"
      ],
      "metadata": {
        "id": "pqYcwiaMgvuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b523ec4-db7d-41f3-af73-4cb77dbba7f2"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46288, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 458
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset=df_subset.drop_duplicates(\"text\", keep=\"first\")\n",
        "df_subset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ufZh7u0EOaX",
        "outputId": "c7e84862-2826-40d9-ecfb-e4964d0aac9b"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46288, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset_clean=df_subset"
      ],
      "metadata": {
        "id": "fCcu3CNXtEbP"
      },
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter by content: "
      ],
      "metadata": {
        "id": "hg0VDadS_J8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter Articles by Title"
      ],
      "metadata": {
        "id": "B0XvJlNRjzcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset_clean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQn97J72_Ain",
        "outputId": "a1e40654-1787-4323-f8e6-21f1b51caed4"
      },
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46288, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 461
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exclude_titles=[\"Beratungsstellen\", \"Termine\",\"Hilfe\",\"Hier_finden_Sie_Hilfe_2sp\",\"was - wann - wo\",\"IN KÜRZE\",\"Kurz notiert :\",\"Dienstbereit - die Woche im Überblick\"\n",
        "]"
      ],
      "metadata": {
        "id": "aZom_rZoY6wZ"
      },
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only keep articles with titles not in the exclude list\n",
        "df_subset_clean=df_subset_clean[df_subset_clean[\"titel\"].apply(filter_title)]\n",
        "df_subset_clean.shape"
      ],
      "metadata": {
        "id": "9zdmzlXGj1af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0df6a6-ee5d-4825-84ed-19c850684a03"
      },
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44467, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter by Text"
      ],
      "metadata": {
        "id": "lGyzcy6unPdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def first_words_filter(text, number_of_words=3):\n",
        "  \"\"\" function to filter article by its first words\n",
        "  Parameters:\n",
        "    - text (str): title that is checked\n",
        "  Returns:\n",
        "    - boolean: returns True if the first n words do not contain any of the words in the list first_words_to_exclude\n",
        "  \"\"\"\n",
        "  # remove special characters\n",
        "  text=re.sub(\"[/\\-!@#$%^&*:.]\", \" \", text[0])\n",
        "  first_words=text.split()[:number_of_words]\n",
        "\n",
        "  # remove whitespace and convert to lower case\n",
        "  first_words=[word.strip().lower() for word in first_words]\n",
        "  for ex in first_words_to_exclude:\n",
        "    if ex.lower() in first_words: \n",
        "      return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "vMhD4MlJvghU"
      },
      "execution_count": 478,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset_clean=df_subset_clean[df_subset_clean[\"text\"].apply(first_words_filter)]\n",
        "df_subset_clean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqnssKJUu5s9",
        "outputId": "93f0b5be-735b-48b5-825a-de3435809e46"
      },
      "execution_count": 514,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35457, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 514
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_words_to_exclude=[# Notufe, Beratungen\n",
        "                        \"Bereitschaftsdienst\", \"Hotline\", \"Notruf\", \"Hilfetelefon\",\"behindertenfahrdienst\",\"Polizeiinspektion\", \n",
        "                        \"Feuerwehr\",\"rettungsdienst\", \"Notdienst\",\"Bereitschaftspraxis\",\"Öffnungszeiten\",\"Vergiftungen\",\n",
        "                        \"Ärztehaus\",\"Selbsthilfegruppe\",\"Leitstelle\",\"Tel\",\"Aids\",\"Ambulante\",\"ACE\", \n",
        "                        \"Club\",\"Interventionsstelle\",\"Frauenberatungsstelle\",\"Rufnummer\",\"Rufnummern\", \"apotheke\", \"hilfsangebot\",\"hilfsangebote\", \n",
        "                        \"opferhilfe\",\"Berufsbildungszentrum\",\"opferschutz\",\n",
        "                        # Kampagnen, Akitonen\n",
        "                        \"kampagne\", \"aktion\", \"ring\",\"initiative\",\n",
        "\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "NLX7MQ6Fs1tg"
      },
      "execution_count": 512,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define regular expressions for weekdays, times, telephone numbers, and street names\n",
        "weekday_regex = re.compile(r'(Mo|Di|Mi|Do|Fr|Sa|So)\\s*[-–]\\s*(Mo|Di|Mi|Do|Fr|Sa|So)')\n",
        "time_regex = re.compile(r'\\d{1,2}[:\\.]\\d{2}\\s*bis\\s*\\d{1,2}[:\\.]\\d{2}\\s*,\\s*(Mo|Di|Mi|Do|Fr|Sa|So)\\s*,\\s*\\d{1,2}\\.\\w+')\n",
        "phone_regex = re.compile(r'\\(?\\d{5}\\)?[/\\s]*\\d{1,5}\\s*\\d{1,5}')\n",
        "street_regex = re.compile(r'[A-Z][a-z]*-?[A-Za-z]+-?[A-Za-z]*\\s*\\d+\\w*')\n"
      ],
      "metadata": {
        "id": "hmjHrVxg_Mai"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lkntG5OJraxM"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to remove the unwanted text snippets from a string\n",
        "def clean_text(text):\n",
        "    text = weekday_regex.sub('', text)\n",
        "    text = time_regex.sub('', text)\n",
        "    text = phone_regex.sub('', text)\n",
        "    text = street_regex.sub('', text)\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "jm4xFHiPAQGR"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the clean_text function to the \"text\" column of the DataFrame\n",
        "df_subset_elinor1['clean_text'] = df_subset_elinor1['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "gcu43QMwATeF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "9a3e1c30-eb5c-42b3-b59f-969ec612b6fe"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-5350693182d4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply the clean_text function to the \"text\" column of the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_subset_elinor1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_subset_elinor1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-76240c742baa>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define a function to remove the unwanted text snippets from a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweekday_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphone_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explode by paragraphs"
      ],
      "metadata": {
        "id": "Aa-slP38P5KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explode \"text\" column\n",
        "df_exploded= df.explode(\"text\")\n",
        "# Create \"artikel_order\" column\n",
        "df_exploded[\"artikel_order\"] = df_exploded.groupby(\"artikel_id\").cumcount() + 1\n"
      ],
      "metadata": {
        "id": "h22XwUD9P25d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Randomly select one paragraph per article"
      ],
      "metadata": {
        "id": "D_4vCxClhzl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "yjOtzi_H58w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_sentences(text):\n",
        "    return len(nltk.sent_tokenize(text))"
      ],
      "metadata": {
        "id": "M2OMY9wc5-Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset_elinor1['num_sentences'] = df_subset_elinor1['text'].apply(count_sentences)"
      ],
      "metadata": {
        "id": "z2Pc_Efw6Aku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to randomly select one row from each group\n",
        "def select_random_row(group):\n",
        "    if group['num_sentences'].max() > 1:\n",
        "        return group[group['num_sentences'] > 1].sample(n=1)\n",
        "    else:\n",
        "        return group.head(1)"
      ],
      "metadata": {
        "id": "iI_MlT6Y9QFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to each group and combine the results\n",
        "random_rows = df_subset_elinor1.groupby('artikel_id').apply(select_random_row).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "vzqDnnIR9b6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = random_rows[['text']]"
      ],
      "metadata": {
        "id": "OXP8Y8Ur-COG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export as csv"
      ],
      "metadata": {
        "id": "0Go0cc9U1kpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"elinor\""
      ],
      "metadata": {
        "id": "ItHRtFVP9vl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final.to_csv(output_path+\"/annotation_test_05_14.csv\", index=False, header = True,\n",
        "                  encoding = 'utf-8')"
      ],
      "metadata": {
        "id": "dJO8Splt9raZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IgSUylz2sAbY"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose\n",
        "\n",
        "This file shows the steps we took to sample and create the annotation dataset."
      ],
      "metadata": {
        "id": "Q1MHyZaI09-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect with Google drive to access data \n",
        "\n",
        "In order to access the data, you first need to create a shortcut of the data folder to your own Gdrive. If you've been granted editing rights, you should be able to edit the content of the folder, i.e. add, move and delete data, create and rename folders, etc."
      ],
      "metadata": {
        "id": "QYjhPHYZ1MVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-gEE8t61TyI",
        "outputId": "c2980edd-eeb5-4d05-a9e0-2914f74b06cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# redirect the working directory of this script to the data folder\n",
        "%cd /content/drive/MyDrive/Work/Frontline/data/\n",
        "#%cd /content/drive/MyDrive/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG1MwJ4Y1U_h",
        "outputId": "c9f92735-29e0-4915-f5b3-78e478d1c006"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1WfnZsqpG1r110J63sMbfS5TpsDOkveiV/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "Ej0F6zHR1Xz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm as tqdm\n",
        "from collections import Counter\n",
        "import os\n",
        "import pandas as pd\n",
        "import re \n",
        "from ast import literal_eval\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = \"filtered_4_26\""
      ],
      "metadata": {
        "id": "Pb-1q-dqzgQH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 1: get csv files "
      ],
      "metadata": {
        "id": "6Ny15n7AO8PV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dfs = []\n",
        "\n",
        "# loop through files \n",
        "for filename in os.listdir(folder_path):\n",
        "    # if csv file, load and add to dfs  \n",
        "    if filename.endswith(\".csv\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        # import csv with text as list object \n",
        "        df = pd.read_csv(file_path, index_col=0, converters={\"text\":literal_eval})\n",
        "        dfs.append(df)\n",
        "# combine files in df\n",
        "df_filtered = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "ktoRDGajzoqi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a random subset of the data "
      ],
      "metadata": {
        "id": "Ieb0Shf71cvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# size of subset we want \n",
        "number = 500"
      ],
      "metadata": {
        "id": "bGL1Cb9R8fLD"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample = df_filtered.sample(number,)# random_state=42)"
      ],
      "metadata": {
        "id": "_7qzAZDi778j"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 2: get a csv file"
      ],
      "metadata": {
        "id": "pFNlGnG7PD23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample_file = pd.read_csv('sample.csv', encoding='utf-8', index_col=0)"
      ],
      "metadata": {
        "id": "RP4BKUzjPIF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 3: Manually selected dataset of relevant articles\n",
        "--> ensuring that the dataset only contains relevant articles, espscially for testing"
      ],
      "metadata": {
        "id": "17Rx0STiu1nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_dv=df_filtered.loc[(11483,14044,62494,49199,11047,14948,10565,31059,58890,20347,55396,56389,5528,18532,59435,8035,27119,12788,59992,21477,10331,26314,45356,61023,31865,48960,44587,17992,14763,60043,20540,4563,13213,6751,43374,41018,38770,24654,21936,29297,1869,33163,60220,61232,57613,48979,33785,51576,8300,7675),:]"
      ],
      "metadata": {
        "id": "bbKfHRI1u7ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select Data\n",
        "--> specify which data set of the three above methods should be used in the following analysis"
      ],
      "metadata": {
        "id": "VXVyMc5mkWGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment for full data set\n",
        "# df_subset=df_filtered\n",
        "# uncomment for random data of 100 from full data set\n",
        "df_subset=df_sample\n",
        "# uncomment for sample data set from csv file\n",
        "# df_subset= df_sample_file\n",
        "# uncomment for manually selected articles \n",
        "# df_subset = subset_dv"
      ],
      "metadata": {
        "id": "5-OJXUYwkhZ2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjust format for export"
      ],
      "metadata": {
        "id": "5FJOlUvd1gHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Methods"
      ],
      "metadata": {
        "id": "7Kwdv6Uim224"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reformat_article(art, min_words=5, max_words=125):\n",
        "  # remove genios styles \n",
        "  art = [re.sub(r'<.*?>', '', x) for x in art]\n",
        "\n",
        "  # remove new line characters and preceeding whitespaces\n",
        "  art = [x.strip() for x in art]\n",
        "\n",
        "  #remove empty paragraphs\n",
        "  art = [x for x in art if x.strip()]\n",
        "\n",
        "  #remove paragraphs that are too long\n",
        "  art = [x for x in art if len(x.split()) < max_words]\n",
        "\n",
        "  #remove paragraphs that are too short, ie. by default 3 or fewer words\n",
        "  art = [x for x in art if len(x.split()) >= min_words]  \n",
        "\n",
        "  return art"
      ],
      "metadata": {
        "id": "beTpoSVOZowg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def occurs(word, text):\n",
        "  \"\"\" function to check if a words occurs in a text\n",
        "  Parameters:\n",
        "    - word (str): word that is searched for\n",
        "    - text (str): text that is searched in \n",
        "  Returns:\n",
        "    - boolean: returns True if word occurs in text, False otherwise\n",
        "  \"\"\"\n",
        "  if len(re.findall(word,text))>0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "P8xAVqhbYsQp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_title(title):\n",
        "  \"\"\" function to filter article by title\n",
        "  Parameters:\n",
        "    - title (str): title that is checked\n",
        "  Returns:\n",
        "    - boolean: returns True if either\n",
        "        - there is no title\n",
        "        - the title does not contain any of the words in the list exclude_titles\n",
        "  \"\"\"\n",
        "  if type(title)!=str:\n",
        "    return True\n",
        "  title=title.strip()\n",
        "  for ex in exclude_titles:\n",
        "    if ex.lower() == title.lower(): \n",
        "      return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "EN5THognY36L"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning text:\n",
        "- remove newline characters\n",
        "- remove paragraphs if too long or short\n",
        "- remove genios styles \n",
        "- remove empty paragraphs"
      ],
      "metadata": {
        "id": "1IRqAQmlPjPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset[\"text\"] = [ reformat_article(art) for art in df_subset[\"text\"]]"
      ],
      "metadata": {
        "id": "uGaaq0t53tzy"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove \"empty\" articles, that wereremove in the previous step\n",
        "df_subset_clean=df_subset[df_subset['text'].notna()] "
      ],
      "metadata": {
        "id": "pqYcwiaMgvuw"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter by content: "
      ],
      "metadata": {
        "id": "hg0VDadS_J8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter Articles by Title"
      ],
      "metadata": {
        "id": "B0XvJlNRjzcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exclude_titles=[\"Beratungsstellen\", \"Termine\",\"Hilfe\"   \n",
        "]"
      ],
      "metadata": {
        "id": "aZom_rZoY6wZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only keep articles with titles not in the exclude list\n",
        "df_subset_clean=df_subset_clean[df_subset_clean[\"titel\"].apply(filter_title)]"
      ],
      "metadata": {
        "id": "9zdmzlXGj1af"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset_clean[\"titel\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqmv-H45nSyg",
        "outputId": "c9b56437-5694-4662-ab9a-9080883ed750"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ohne Titel                                                                                     47\n",
              "Wuhan­ - die Stadt, die wieder lebt                                                             3\n",
              "Häusliche Gewalt: In Gewahrsam                                                                  2\n",
              "Wenn der Partner zuschlägt                                                                      2\n",
              "Mehr Frauen Opfer von Gewalt                                                                    1\n",
              "                                                                                               ..\n",
              "Fälle häuslicher Gewalt im ausgehenden Jahr registiert                                          1\n",
              "Weniger Fälle häuslicher Gewalt                                                                 1\n",
              "Mann nach Stichverletzung notoperiert                                                           1\n",
              "Finanzielle Mittel zum Betrieb des Frauenschutzhauses reichen nicht aus: 61000 Euro Defizit     1\n",
              "Anklage fordert lebenslange Haft                                                                1\n",
              "Name: titel, Length: 326, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter by Text"
      ],
      "metadata": {
        "id": "lGyzcy6unPdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define regular expressions for weekdays, times, telephone numbers, and street names\n",
        "weekday_regex = re.compile(r'(Mo|Di|Mi|Do|Fr|Sa|So)\\s*[-–]\\s*(Mo|Di|Mi|Do|Fr|Sa|So)')\n",
        "time_regex = re.compile(r'\\d{1,2}[:\\.]\\d{2}\\s*bis\\s*\\d{1,2}[:\\.]\\d{2}\\s*,\\s*(Mo|Di|Mi|Do|Fr|Sa|So)\\s*,\\s*\\d{1,2}\\.\\w+')\n",
        "phone_regex = re.compile(r'\\(?\\d{5}\\)?[/\\s]*\\d{1,5}\\s*\\d{1,5}')\n",
        "street_regex = re.compile(r'[A-Z][a-z]*-?[A-Za-z]+-?[A-Za-z]*\\s*\\d+\\w*')\n"
      ],
      "metadata": {
        "id": "hmjHrVxg_Mai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lkntG5OJraxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to remove the unwanted text snippets from a string\n",
        "def clean_text(text):\n",
        "    text = weekday_regex.sub('', text)\n",
        "    text = time_regex.sub('', text)\n",
        "    text = phone_regex.sub('', text)\n",
        "    text = street_regex.sub('', text)\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "jm4xFHiPAQGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the clean_text function to the \"text\" column of the DataFrame\n",
        "df_subset_elinor1['clean_text'] = df_subset_elinor1['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "gcu43QMwATeF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "f1af5a82-73ac-4502-c413-21cb24173f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5350693182d4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply the clean_text function to the \"text\" column of the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_subset_elinor1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_subset_elinor1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_subset_elinor1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explode by paragraphs"
      ],
      "metadata": {
        "id": "Aa-slP38P5KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explode \"text\" column\n",
        "df_exploded= df.explode(\"text\")\n",
        "# Create \"artikel_order\" column\n",
        "df_exploded[\"artikel_order\"] = df_exploded.groupby(\"artikel_id\").cumcount() + 1\n"
      ],
      "metadata": {
        "id": "h22XwUD9P25d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Randomly select one paragraph per article"
      ],
      "metadata": {
        "id": "D_4vCxClhzl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "yjOtzi_H58w4",
        "outputId": "98541029-9e68-4fd6-cb10-7fad62828741",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_sentences(text):\n",
        "    return len(nltk.sent_tokenize(text))"
      ],
      "metadata": {
        "id": "M2OMY9wc5-Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset_elinor1['num_sentences'] = df_subset_elinor1['text'].apply(count_sentences)"
      ],
      "metadata": {
        "id": "z2Pc_Efw6Aku",
        "outputId": "6435384f-4e1f-430c-f69c-bc905cba9792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-229108de2b5b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_subset_elinor1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_sentences'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_subset_elinor1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_subset_elinor1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to randomly select one row from each group\n",
        "def select_random_row(group):\n",
        "    if group['num_sentences'].max() > 1:\n",
        "        return group[group['num_sentences'] > 1].sample(n=1)\n",
        "    else:\n",
        "        return group.head(1)"
      ],
      "metadata": {
        "id": "iI_MlT6Y9QFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to each group and combine the results\n",
        "random_rows = df_subset_elinor1.groupby('artikel_id').apply(select_random_row).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "vzqDnnIR9b6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = random_rows[['text']]"
      ],
      "metadata": {
        "id": "OXP8Y8Ur-COG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export as csv"
      ],
      "metadata": {
        "id": "0Go0cc9U1kpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"elinor\""
      ],
      "metadata": {
        "id": "ItHRtFVP9vl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final.to_csv(output_path+\"/annotation_test_05_14.csv\", index=False, header = True,\n",
        "                  encoding = 'utf-8')"
      ],
      "metadata": {
        "id": "dJO8Splt9raZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}